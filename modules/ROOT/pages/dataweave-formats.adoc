= Formats Supported by DataWeave
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]
:keywords: studio, anypoint, esb, transform, transformer, format, aggregate, rename, split, filter convert, xml, json, csv, pojo, java object, metadata, dataweave, data weave, datamapper, dwl, dfl, dw, output structure, input structure, map, mapping

DataWeave can read and write many types of data formats, such as JSON, XML, and many others. DataWeave supports these formats (or mime types) as input and output:

[cols="2,2", options="header"]
|===
| Mime Type | Supported Formats

| `application/csv`
| <<format_csv>>

| `application/dw`
| <<format_dataweave>> (for testing a DataWeave expression)

| `multipart/*`
| <<format_form_data>>

| `application/flatfile`
| <<format_flat_file>>, <<format_cobol_copybook>>, <<format_fixed_width>>

| `application/java`
| <<format_java>>, <<format_enum>>

| `application/json`
| <<format_json>>

| `application/octet-stream`
| For binary.

| `application/yaml`
| For Yaml Data Format.

| `application/xml`
| <<format_xml>>, <<format_cdata>>

| `application/xlsx`
| <<format_excel>>

| `application/x-www-form-urlencoded`
| <<format_url_encoded>>

| `text/plain`
| For plain text.
|===
// TODO: PLAIN TEXT SECTION? <<format_plain_text>>

== Setting Mime Types

You can specify the mime type for the input and output data that flows through a Mule app.

For DataWeave transformations, you can specify the mime type for the output data. For example, you might set the `output` header directive of an expression in the Transform component or a Write operation to `output application/json` or `output application/csv`. This example sets the mime type through a File Write operation to ensure that a format-specific writer, the CSV writer, outputs the payload in CSV format:

.Example: Mime Type for the CSV Writer
[source,xml,linenums]
----
<file:write doc:name="Write" config-ref="File_Config" path="my_transform">
  <file:content ><![CDATA[#[output application/csv --- payload]]]></file:content>
</file:write>
----

For input data, format-specific readers for Mule sources (such as the On New File listener), Mule operations (such as Read and HTTP Request operations), and DataWeave expressions attempt to infer the mime type from metadata that is associated with input payloads, attributes, and variables in the Mule event. When the mime type cannot be inferred from the metadata (and when that metadata is not static), Mule sources and operations allow you to specify the mime type for the reader. For example, you might set the mime type for the On New File listener to  `outputMimeType='application/csv'` for CSV file _input_. This setting provides information about the file format to the CSV reader.

.Example: Mime Type for the CSV Reader
[source,xml,linenums]
----
<file:listener doc:name="On New File"
  config-ref="File_Config"
  outputMimeType='application/csv'>
</file:listener>
----

Note that reader settings _are not_ used to perform a transformation from one format to another. They simply help the reader interpret the format of the input.

You can also set special reader and writer properties for use by the format-specific reader or writer of a source, operation, or component. See <<reader_writer_properties, Using Reader and Writer Properties>>.

[[reader_writer_properties]]
== Using Reader and Writer Properties

In some cases, it is necessary to modify or specify aspects of the format through format-specific properties. For example, you can specify CSV input and output properties, such as the `separator` (or delimiter) to use in the CSV file. For Cobol copybook, you need to specify the path to a schema file using the `schemaPath` property.

You can append reader properties to the mime type (`outputMimeType`) attribute for certain components in your Mule app. Listeners and Read operations accept these settings. For example, this On New File listener example identifies the `,` separator for a CSV input file:

.Example: Properties for the CSV Reader
[source,xml,linenums]
----
<file:listener doc:name="On New File" config-ref="File_Config" outputMimeType='application/csv; separator=","'>
  <scheduling-strategy >
    <fixed-frequency frequency="45" timeUnit="SECONDS"/>
  </scheduling-strategy>
  <file:matcher filenamePattern="comma_separated.csv" />
</file:listener>
----

Note that the `outputMimeType` setting above helps the CSV _reader_ interpret the format and delimiter of the input `comma_separated.csv` file, not the writer.

To specify the output format, you can provide the mime type and any writer properties for the writer, such as the CSV or JSON writer used by a File Write operation. For example, you might need to write a pipe (`|`) delimiter in your CSV output payload, instead of some other delimiter used in the input. To do this, you append the property and its value to the `output` directive of a DataWeave expression. For example, this Write operation specifies the pipe as a `separator`:

.Example: output Directive for the CSV Writer
[source,xml,linenums]
----
<file:write doc:name="Write" config-ref="File_Config" path="my_transform">
  <file:content ><![CDATA[#[output application/csv separator="|" --- payload]]]></file:content>
</file:write>
----

The sections below list the format-specific reader and writer properties available for each supported format.

[[format_cobol_copybook]]
== Cobol Copybook

Mime Type: `application/flatfile`

// TODO: <<flat file>>
A Cobol copybook is a type of flat file that describes the layout of records and fields in a Cobol data file.

The Transform component provides settings for handling the Cobol copybook format. For example, you can import a Cobol definition into the Transform component and use it for your Copybook transformations.

[[cobol_metadata]]
=== Importing a Copybook Definition

When you import a Copybook definition, the Transform component converts the definition to a flat file schema that you can reference with `schemaPath` property.

To import a copybook definition:

. Right-click the input payload in the Transform component in Studio, and select Set Metadata to open the Set Metadata Type dialog.
+
Note that you need to create a metadata type before you can import a copybook definition.
+
. Provide a name for your copybook metadata, such as `copybook`.
. Select the Copybook type from the Type drop-down menu.
. Import your copybook definition file.
. Click Select.
+
.Importing a Copybook Definition File
image::copybook-import.png[Importing a Copybook Definition]

For example, assume that you have a copybook definition file (`mailing-record.cpy`) that looks like this:

----
01  MAILING-RECORD.
    05  COMPANY-NAME            PIC X(30).
    05  CONTACTS.
        10  PRESIDENT.
            15  LAST-NAME       PIC X(15).
            15  FIRST-NAME      PIC X(8).
        10  VP-MARKETING.
            15  LAST-NAME       PIC X(15).
            15  FIRST-NAME      PIC X(8).
        10  ALTERNATE-CONTACT.
            15  TITLE           PIC X(10).
            15  LAST-NAME       PIC X(15).
            15  FIRST-NAME      PIC X(8).
    05  ADDRESS                 PIC X(15).
    05  CITY                    PIC X(15).
    05  STATE                   PIC XX.
    05  ZIP                     PIC 9(5).
----
Note: Copybook definitions must always begin with a `01` entry. A separate record type is generated for each `01` definition in your copybook (there must be at least one `01` definition for the copybook to be usable, so add one using an arbitrary name at the start of the copybook if none is present). If there are multiple `01` definitions in the copybook file, you can select which definition to use in the transform from the dropdown list.

When you import the schema, the Transform component converts the copybook file to a flat file schema that it stores in the `src/main/resources/schema` folder of your Mule project. In flat file format, the copybook definition above looks like this:

----
form: COPYBOOK
id: 'MAILING-RECORD'
values:
- { name: 'COMPANY-NAME', type: String, length: 30 }
- name: 'CONTACTS'
  values:
  - name: 'PRESIDENT'
    values:
    - { name: 'LAST-NAME', type: String, length: 15 }
    - { name: 'FIRST-NAME', type: String, length: 8 }
  - name: 'VP-MARKETING'
    values:
    - { name: 'LAST-NAME', type: String, length: 15 }
    - { name: 'FIRST-NAME', type: String, length: 8 }
  - name: 'ALTERNATE-CONTACT'
    values:
    - { name: 'TITLE', type: String, length: 10 }
    - { name: 'LAST-NAME', type: String, length: 15 }
    - { name: 'FIRST-NAME', type: String, length: 8 }
- { name: 'ADDRESS', type: String, length: 15 }
- { name: 'CITY', type: String, length: 15 }
- { name: 'STATE', type: String, length: 2 }
- { name: 'ZIP', type: Integer, length: 5, format: { justify: ZEROES, sign: UNSIGNED } }
----

After importing the copybook, you can use the `schemaPath` property to reference the associated flat file through the `output` directive. For example: `output application/flatfile  schemaPath="src/main/resources/schemas/mailing-record.ffd"`

=== Supported Copybook Features

Not all copybook features are supported by the Cobol Copybook format in DataWeave. In general, the format supports most common usages and simple patterns, including:

* USAGE of DISPLAY, BINARY (COMP), and PACKED-DECIMAL (COMP-3)
* PICTURE clauses for numeric values consisting only of:
** '9' - One or more numeric character positions
** 'S' - One optional sign character position, leading or trailing
** 'V' - One optional decimal point
** 'P' - One or more decimal scaling positions
* PICTURE clauses for alphanumeric values consisting only of 'X' character positions
* Repetition counts for '9', 'P', and 'X' characters in PICTURE clauses (as in `9(5)` for a 5-digit numeric value)

Unsupported features include:

* Alphanumeric-edited PICTURE clauses
* Numeric-edited PICTURE clauses with insertion or replacement
* Special level-numbers:
** Level 66 - Alternate name for field or group
** Level 77 - Independent data item
** Level 88 - Condition names (equivalent to an enumeration of values)
* USAGE of COMP-1, COMP-2, or COMP-5
* REDEFINES clause (used to provide different views of the same portion of record data)

=== Common Copybook Import Issues

The most common issue with copybook imports is a failure to follow the Cobol standard for input line regions. The copybook import parsing ignores the contents of columns 1-6 of each line, and ignores all lines with an '*' (asterisk) in column 7. It also ignores everything beyond column 72 in each line. This means that all your actual data definitions need to be within columns 8 through 72 of input lines.

Tabs in the input are not expanded because there is no defined standard for tab positions. Each tab character is treated as a single space character when counting copybook input columns.

Indentation is ignored when processing the copybook, with only level-numbers treated as significant. This is not normally a problem, but it means that copybooks might be accepted for import even though they are not accepted by Cobol compilers.

Both warnings and errors might be reported as a result of a copybook import. Warnings generally tell of unsupported or unrecognized feature, which might or might not be significant. Errors are notifications of a problem that means the generated schema (if any) will not be a completely accurate representation of the copybook. You should review any warnings or errors reported and decide on the appropriate handling, which might be simply accepting the schema as generated, modifying the input copybook, or modifying the generated schema.

=== Reader Properties (for Cobol Copybook)

When defining an input of type Copybook, there are a few optional parameters you can add in the XML definition of your Mule project to customize how the data is parsed.

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`schemaPath` | string | | Location in your local disk of the schema file used to parse your input
|`segmentIdent` |string |  | In case the schema file defines multiple different structures, this field selects which to use
|`missingValues` | string | nulls | How missing values are represented in the input data:

* `none`: treat all data as actual values
* `spaces`: interpret a field consisting of only spaces as a missing value
* `zeroes`: interpret numeric fields consisting of only '0' characters and character fields consisting of only spaces as missing values
* `nulls`: interpret a field consisting only of 0 bytes as a missing value

| `recordParsing` | string | strict a| expected separation between lines/records:

* `strict`: line break expected at exact end of each record
* `lenient`: line break used but records may be shorter or longer than schema specifies
* `noTerminator`: means records follow one another with no separation
|===

Note that schemas with type `Binary` or `Packed` don't allow for the detection of line breaks, so setting `recordParsing` to `lenient` only allow for long records to be handled, not short ones. These schemas only work with certain single-byte character encodings (so not with UTF-8 or any multibyte format).

////
You can set these properties through the Transform component or through the XML of your Mule app.

XML example:

[source,xml,linenums]
----
<dw:input-payload mimeType="application/flatfile" >
  <dw:reader-property name="schemaPath" value="myschema.ffs"/>
  <dw:reader-property name="segmentIdent" value="structure1"/>
</dw:input-payload>
----
////

=== Writer Properties (for Cobol Copybook)

When defining an output of type Copybook, there are a few optional parameters you can add to the DataWeave output directive to customize how the data is written:

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`schemaPath` |string | |Path where the schema file to be used is located
|`segmentIdent` |string | |In case the schema file defines multiple formats, indicates which of them to use
|`encoding` |string | UTF-8 | Output character encoding

|`missingValues`| string | nulls | How to represent optional values missing from the supplied map:

* `spaces`: fill the field with spaces
* `nulls`: use 0 bytes

|`recordTerminator` | string | Standard Java line termination for the system | Termination for every line/record. In Mule runtime versions 4.0.4 and older, this is only used as a separator when there are multiple records. Possible values: `lf, cr, crlf, none`. Values translate directly to character codes (`none` leaves no termination on each record).
|`trimValues` |boolean |`false` |Trim string values longer than field length by truncating trailing characters
|===

.Example: output Directive
[source,dataweave,linenums]
----
output application/flatfile schemaPath="src/main/resources/schemas/QBReqRsp.esl", structureIdent="QBResponse"
----

[[format_csv]]
== CSV

Mime Type: `application/csv`

CSV content is modeled in DataWeave as a list of objects, where every record is an object and every field in it is a property. For example:

.DataWeave Script that Outputs CSV
[source,dataweave,linenums]
----
%dw 2.0
output application/csv
---
[
  {
    "Name":"Mariano",
    "Last Name":"De achaval"
  },
  {
    "Name":"Leandro",
    "Last Name":"Shokida"
  }
]
----

.CSV Output
[source,text,linenums]
----
Name,Last Name
Mariano,De achaval
Leandro,Shokida
----

=== Reader Properties (for CSV)

In CSV, you can assign any special character as the indicator for separating fields, toggling quotes, or escaping quotes. Make sure you know what special characters are being used in your input so that DataWeave can interpret it correctly.

When defining an input of type CSV, there are a few optional parameters you can add in the XML definition of your Mule project to customize how the data is parsed.

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`separator` |char | `,` |Character that separates one field from another
|`quote` |char | `"` |Character that delimits the field values
|`escape` |char | `\` |Character used to escape occurrences of the separator or quote character within field values
|`bodyStartLineNumber`| number | `0` | The line number where the body starts.
|`ignoreEmptyLine` |boolean | `true` | defines if empty lines are ignored
|`header` |boolean |`true` |Indicates if the first line of the output shall contain field names
|`headerLineNumber` | number | `0` | the line number where the header is located
|`streaming` | boolean | `false` | Used for streaming input CSV. (Use only if entries are accessed sequentially.)
|===

* When `header=true` you can then access the fields within the input anywhere by name, for example: `payload.userName`.
* When `header=false` you must access the fields by index, referencing first the entry and then the field, for example: `payload[107][2]`

////
TODO: NEEDS UPDATE
* XML example:
+
[source,xml,linenums]
----
<dw:transform-message metadata:id="33a08359-5085-47d3-aa5f-c7dd98bb9c61"
  doc:name="Transform">
    <dw:input-payload
      <!-- Boolean that defines if the first line in the data contains headers -->
      <dw:reader-property name="header" value="false" />
      <!-- Character that separates fields, `','` by default -->
      <dw:reader-property name="separator" value="," />
      <!-- Character that defines quoted text, `" "` by default -->
      <dw:reader-property name="quote" value="&quot;" />
      <!-- Character that escapes quotes, `\` by default -->
      <dw:reader-property name="escape" value="\" />
    </dw:input-payload>
 		<dw:set-payload>
        <![CDATA[
            %dw 2.0
            output application/java
            ---
            // Your transformation script goes here
        ]]>
    </dw:set-payload>
</dw:transform-message>
----
+
* Transform component example:
image::<missing>dataweave-formats-580be.png[]
// TODO CHECK IMAGE
////

[[writer_properties_csv]]
=== Writer Properties (for CSV)

When defining an output of type CSV, there are a few optional parameters you can add to the output directive to customize how the data is parsed:

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`separator` |char |, |Character that separates one field from another
|`encoding` |string | |The character set to be used for the output
|`quote` |char |" |Character that delimits the field values
|`escape` |char | \ |Character used to escape occurrences of the separator or quote character within field values
|`lineSeparator`|string | system line ending default | line separator to be used. Example: "\r\n"
|`header` |boolean |true |Indicates if the first line of the output shall contain field names
|`quoteHeader` |boolean |false |Indicates header values should be quoted
|`quoteValues` |boolean |false |Indicates if every value should be quoted whether or not it contains special characters within
|===

All of these parameters are optional. A CSV output directive might for example look like this:

.Example: output Directive
[source,dataweave,linenums]
----
output text/csv separator=";", header=false, quoteValues=true
----

=== Defining a Metadata Type (for CSV)

In the Transform component, you can define a CSV type through the following methods:

* By providing a sample file.
* Through a graphical editor that allows you to set up each field manually.
+
image::dataweave-formats-4a556.png[]

[[format_dataweave]]
== DataWeave

Mime Type: `application/dw`

The DataWeave format is the canonical format for all transformations. Using it can helpful for understanding how input data is interpreted before it is transformed to a new format.

This example shows how XML input is expressed in the DataWeave format.

.Input XML
[source,xml,linenums]
----
<employees>
  <employee>
    <firstname>Mariano</firstname>
    <lastname>DeAchaval</lastname>
  </employee>
  <employee>
    <firstname>Leandro</firstname>
    <lastname>Shokida</lastname>
  </employee>
</employees>
----

.Output in DataWeave Format
[source,dataweave,linenums]
----
{
  employees: {
    employee: {
      firstname: "Mariano",
      lastname: "DeAchaval"
    },
    employee: {
      firstname: "Leandro",
      lastname: "Shokida"
    }
  }
} as Object {encoding: "UTF-8", mimeType: "text/xml"}
----

[[format_excel]]
== Excel

Mime Type: `application/xlsx`

Only `.xlsx` files are supported (Excel 2007). `.xls` files are not supported by Mule runtime.

// TODO: IS THIS ACCURATE?
An Excel workbook is a sequence of sheets. In DataWeave, this is mapped to an object where each sheet is a key. Only one table is allowed per Excel sheet. A table is expressed as an array of rows. A row is an object where its keys are the columns and the values the cell content.

.Input

image::dataweave-formats-exceltable.png[]

.DataWeave Script that Outputs XLSX
[source,dataweave,linenums]
----
output application/xlsx header=true
---
{
  Sheet1: [
    {
      Id: 123,
      Name: George
    },
    {
      Id: 456,
      Name: Lucas
    }
  ]
}
----

=== Reader Properties (for Excel)

When defining an input of type Excel, there are a few optional parameters you can add in the XML definition of your Mule project to customize how the data is parsed.

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`header` | boolean | true |	defines if the Excel tables contain headers. When set to false, column names are used. (A, B, C, ...)
|`ignoreEmptyLine`	| boolean | true | defines if empty lines are ignored
|`tableOffset` | string | A1 |	The position of the first cell of the tables
|===

////
TODO: UPDATE
* XML example:
+
[source,xml,linenums]
----
<dw:transform-message metadata:id="33a08359-5085-47d3-aa5f-c7dd98bb9c61"
  doc:name="Transform">
    <dw:input-payload
      <!-- Boolean that defines if the first line in the data contains headers -->
      <dw:reader-property name="header" value="true" />
      <!-- Boolean that defines if empty lines are ignored -->
      <dw:reader-property name="ignoreEmptyLine" value="false" />
      <!-- Defines that defines what cell to start reading from. In this case Column A is ignored, and all rows above 9 -->
      <dw:reader-property name="tableOffset" value="B9" />
    </dw:input-payload>
    <dw:set-payload>
        <![CDATA[
            %dw 2.0
            output application/java
            ---
            // Your transformation script goes here
        ]]>
    </dw:set-payload>
</dw:transform-message>
----

* Transform component
////
//TODO: IS THIS AVAILABLE IN STUDIO 7?
//image:dataweave-formats-excell-reader.png[]

=== Writer Properties (for Excel)

When defining an output of type Excel, there are a few optional parameters you can add to the output directive to customize how the data is parsed:

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`header` | boolean | true |	defines if the Excel tables contain headers. When there are no headers, column names are used. (A, B, C, ...)
|`ignoreEmptyLine`	| boolean | true | defines if empty lines are ignored
|`tableOffset` | string | A1 |	The position of the first cell of the tables
|===

All of these parameters are optional. A DataWeave output directive might for Excel might look like this:

.Example: output Directive
[source,dataweave,linenums]
----
output application/xlsx header=true
----

=== Defining a Metadata Type (for Excel)

In the Transform component, you can define a Excel type through the following method:

* Through a graphical editor that allows you to set up each field manually.

//TODO: CHECK THIS:
image:dataweave-formats-excel-metadata.png[]

[[format_fixed_width]]
== Fixed Width

Mime Type: `application/flatfile`

// TODO: LINK <<Flat File>> here.
Fixed width types are technically considered a type of Flat File format, but when selecting this option the Transform component offers you settings that are better tailored to the needs of this format.

=== Reader Properties (for Fixed Width)

When defining an input of type Fixed Width, there are a few optional parameters you can add in the XML definition of your Mule project to customize how the data is parsed.

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`schemaPath`| string | | Location in your local disk of the schema file used to parse your input. The Schema must have an `.FFD` extension.
|`missingValues`| string | spaces a| How missing values are represented in the input data:

* `none`: treat all data as actual values
* `spaces`: interpret a field consisting of only spaces as a missing value
* `zeroes`: interpret numeric fields consisting of only '0' characters and character fields consisting of only spaces as missing values
* `nulls`: interpret a field consisting only of 0 bytes as a missing value

| `recordParsing` | string | strict a| expected separation between lines/records:

* `strict`: line break expected at exact end of each record
* `lenient`: line break used but records may be shorter or longer than schema specifies
* `noTerminator`: means records follow one another with no separation
|===

////
* XML example:
[source,xml,linenums]
----
<dw:input-payload mimeType="application/flatfile" >
  <dw:reader-property name="schemaPath" value="myschema.ffd"/>
  <dw:reader-property name="structureIdent" value="structure1"/>
</dw:input-payload>
----
+
* Transform component
////

//TODO: DOES THIS EXIST IN STUDIO 7
//image:dataweave-formats-6e5e4.png[]

=== Writer Properties (for Fixed Width)

When defining an output of type fixed width there are a few optional parameters you can add to the output directive to customize how the data is written:

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`schemaPath` |string | |Path where the schema file to be used is located
|`encoding` |string | UTF-8 | Output character encoding
|`missingValues` |string | spaces a| How to represent optional values missing from the supplied map:

* spaces: fill the field with spaces
* nulls: use 0 bytes

|`recordTerminator` | string | standard Java line termination for the system | Termination for every line/record. In Mule runtime versions 4.0.4 and older, this is only used as a separator when there are multiple records. Possible values: `lf, cr, crlf, none`. Values translate directly to character codes (`none` leaves no termination on each record).
|`trimValues` |boolean |`false` |Trim string values longer than field length by truncating trailing characters
|===

All of these parameters are optional. A DataWeave output directive might for Excel might look like this:

.Example: output Directive
[source,text,linenums]
----
output application/flatfile schemaPath="src/main/resources/schemas/payment.ffd", encoding="UTF-8"
----

=== Defining a Metadata Type (for Fixed Width)

In the Transform component, you can define a Fixed Width type through the following methods:

* By providing a sample file.
* By pointing to a Flat File schema file.
* Through a graphical editor that allows you to set up each field manually.
+
image::dataweave-formats-27b3c.png[]
// TODO IS IMAGE OKAY?

[[format_flat_file]]
== Flat File

Mime Type: `application/flatfile`

=== Reader Properties (for Flat File)

When defining an input of type Flat File, there are a few optional parameters you can add in the XML definition of your Mule project to customize how the data is parsed.

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`schemaPath`| string | | Location in your local disk of the schema file used to parse your input. The Schema must have an `.ESL` extension.
|`structureIdent`|string |  | The schema file might define multiple different structures, this field selects which to use. In case the schema only defines one, you also need to explicitly select that one through this field.
|`missingValues`| string | spaces a| How missing values are represented in the input data:

* `none`: treat all data as actual values
* `spaces`: interpret a field consisting of only spaces as a missing value
* `zeroes`: interpret numeric fields consisting of only '0' characters and character fields consisting of only spaces as missing values
* `nulls`: interpret a field consisting only of 0 bytes as a missing value

| `recordParsing` | string | strict a| expected separation between lines/records:

* `strict`: line break expected at exact end of each record
* `lenient`: line break used but records may be shorter or longer than schema specifies
* `noTerminator`: means records follow one another with no separation
|===

////

* XML example:
[source,xml,linenums]
----
<dw:input-payload mimeType="application/flatfile" >
  <dw:reader-property name="schemaPath" value="myschema.esl"/>
  <dw:reader-property name="structureIdent" value="structure1"/>
</dw:input-payload>
----
////

Note that schemas with type `Binary` or `Packed` don't allow for line break detection, so setting `recordParsing` to `lenient` only allows long records to be handled, not short ones. These schemas also currently only work with certain single-byte character encodings (so not with UTF-8 or any multibyte format).

=== Writer Properties (for Flat File)

When defining an output of type flat file there are a few optional parameters you can add to the output directive to customize how the data is written:

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`schemaPath` |string | |Path where the schema file to be used is located
|`structureIdent` |string | |In case the schema file defines multiple formats, indicates which of them to use
|`encoding` |string | UTF-8 | Output character encoding
|`missingValues`| string | spaces a| How to represent optional values missing from the supplied map:

* `spaces`: fill the field with spaces
* `nulls`: use 0 bytes

|`recordTerminator`| string | standard Java line termination for the system | Termination for every line/record. In Mule runtime versions 4.0.4 and older, this is only used as a separator when there are multiple records. Possible values: `lf, cr, crlf, none`. Values translate directly to character codes (`none` leaves no termination on each record).
|`trimValues` |boolean |`false` |Trim string values longer than field length by truncating trailing characters
|===

.DataWeave Script that Output a Flat File
[source,dataweave,linenums]
----
%dw 2.0
output application/flatfile schemaPath="src/main/resources/test-data/QBReqRsp.esl", structureIdent="QBResponse"
---
payload
----

=== Defining a Metadata Type (for Flat File)

In the Transform component, you can define a Flat File type by pointing to a schema file.

[[format_form_data]]
== Multipart (Form-Data)

Format: `multipart/form-data`

DataWeave supports multipart subtypes, in particular `form-data`. These formats allow
handling several different data parts in a single payload, regardless of the format each
part has. To distinguish the beginning and end of a part, a boundary is used and metadata for
each part can be added through headers.

Below you can see a raw `multipart/form-data` payload with a `34b21` boundary consisting of 3 parts:

* a `text/plain` one named `text`
* an `application/json` file (`a.json`) named `file1`
* a `text/html` file (`a.html`) named `file2`

.Raw Multipart
[source,text,linenums]
----
--34b21
Content-Disposition: form-data; name="text"
Content-Type: text/plain

Book
--34b21
Content-Disposition: form-data; name="file1"; filename="a.json"
Content-Type: application/json

{
  "title": "Java 8 in Action",
  "author": "Mario Fusco",
  "year": 2014
}
--34b21
Content-Disposition: form-data; name="file2"; filename="a.html"
Content-Type: text/html

<!DOCTYPE html>
<title>
  Available for download!
</title>
--34b21--
----

Within a DataWeave script, you can access and transform data from any of the parts by selecting the `parts` element.
Navigation can be array based or key based when parts feature a name to reference them by.
The part's data can be accessed through the `content` keyword while headers can be accessed
through the `headers` keyword.

The following script, for example, would produce `Book:a.json` considering
the previous payload:

.Reading Multipart Content
[source,dataweave,linenums]
----
%dw 2.0
output text/plain
---
payload.parts.text.content ++ ':' ++ payload.parts[1].headers.'Content-Disposition'.filename
----

You can generate multipart content through DataWeave building an object with a list of parts
each containing it's headers and content. Below you can find a DataWeave script
that produces the raw multipart data previously analyzed, considering the HTML data
is available in the payload.

.Writing Multipart Content
[source,dataweave,linenums]
----
%dw 2.0
output multipart/form-data
boundary='34b21'
---
{
  parts : {
    text : {
      headers : {
        "Content-Type": "text/plain"
      },
      content : "Book"
    },
    file1 : {
      headers : {
        "Content-Disposition" : {
            "name": "file1",
            "filename": "a.json"
        },
        "Content-Type" : "application/json"
      },
      content : {
        title: "Java 8 in Action",
        author: "Mario Fusco",
        year: 2014
      }
    },
    file2 : {
      headers : {
        "Content-Disposition" : {
            "filename": "a.html"
        },
        "Content-Type" : payload.^mimeType
      },
      content : payload
    }
  }
}
----

Notice that the key will determine the part's name if not explicitly provided in
the `Content-Disposition` header and that DataWeave can handle content from supported formats
as well as references to unsupported ones, as HTML.

=== Reader Properties (for Multipart)

You can set the boundary for the reader to use when it analyzes the data.

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`boundary` | String | | A String to delimit parts.
|===

Note that in the DataWeave `read` function, you can also pass the property as an optional parameter. The scope of the property is limited to the DataWeave script where you call the function.

=== Writer Properties (for Multipart)

The writer output form data using the DataWeave header directive:

.Example: output Directive
[source,dataweave,linenums]
----
output multipart/form-data
----

In the output directive, you can also set a property for the writer to use when it outputs the data in the specified format.

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default |Description
|`boundary` | String | Randomly autogenerated | A String to delimit parts.
|===

For example, if a boundary is `34b21`, then you can pass this:

.Example: output Directive
[source,dataweave,linenums]
----
output multipart/form-data
boundary=34b21
----

Note that in the DataWeave `write` function, you can also pass the property as an optional parameter. The scope of the property is limited to the DataWeave script where you call the function.

[TIP]
--
Multipart is typically, but not exclusively, used in HTTP where the boundary is
shared through the `Content-Type` header, both for reading and writing content.
--

[[format_java]]
== Java

Mime Type: `application/java`

This table shows the mapping between Java objects to DataWeave types.

[cols="3,1", options="header"]
|===
|Java Type
|DataWeave Type

|`Collections/Array/Iterator/Iterable`
| xref:dataweave-types.adoc#array[Array]

|`String/CharSequence/Char/Enum/Class`
| xref:dataweave-types.adoc#string[String]

|`int/Short/Long/BigInteger/Flat/Double/BigDecimal`
|xref:dataweave-types.adoc#number[Number]

|`Calendar/XmlGregorianCalendar`
|xref:dataweave-types.adoc#datetime[DateTime]

|`TimeZone`
|xref:dataweave-types.adoc#timezone[TimeZone]

|`sql.Date/util.Date`
|xref:dataweave-types.adoc#date[Date]

|`Bean/Map`
|xref:dataweave-types.adoc#object[Object]

|`InputStream/Array[Byte]`
|xref:dataweave-types.adoc#binary[Binary]

|`java.lang.Boolean`
|xref:dataweave-types.adoc#boolean[Boolean]
|===

=== Custom Types (for Java)

There are a couple of custom Java types:

* `class`
* `Enum`

=== Metadata property `class` (for Java)

Java developers use the `class` metadata key as hint for what class needs to be created and sent as an input. If this is not explicitly defined, DataWeave tries to infer from the context or it assigns it the default values:

 * `java.util.HashMap` for objects
 * `java.util.ArrayList` for lists

[source,dataweave,linenums]
----
%dw 2.0
type user = Object { class: "com.anypoint.df.pojo.User"}
output application/json
---
{
  name : "Mariano",
  age : 31
} as user

----

The code above defines the type of the required input as an instance of `com.anypoint.df.pojo.User`.

[[format_enum]]
=== Enum Custom Type (for Java)

In order to put an enum value in a `java.util.Map`, the DataWeave Java module defines a custom type called `Enum`. It allows you to specify that a given string should be handled as the name of a specified enum type. It should always be used with the class property with the java class name of the enum.

=== Defining a Metadata Type (for Java)

In the Transform component, you can define a Java type through the following method:

* By providing a sample object

[[format_json]]
== JSON

Mime Type: `application/json`

JSON data structures are mapped to DataWeave data structures because they share a lot of similarities.

=== Writer Properties (for JSON)

When defining an output of type JSON, there are a few optional parameters you can add to the output directive to customize how the data is parsed:

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default |Description
|`indent`| boolean | true | Defines if the JSON code will be indented for better readability, or if it will be compressed into a single line
|`encoding`| string | UTF-8 |The character set to be used for the output
|`bufferSize`| number | 153600 | The size of the buffer writer
|`inlineCloseOn` | string | | When the writer should use inline close tag. Possible values = empty/none
|`skipNullOn`| string | | Possible values = `elements`/`attributes`/`everywhere`. See <<Skip Null On>>
|`duplicateKeyAsArray`| boolean | false | JSON language doesn't allow duplicate keys with one same parent, this usually raises an exception. If set to true, the output contains a single key that points to an array containing all the values assigned to it.
|===

.Example: output Directive
[source,dataweave,linenums]
----
output application/json indent=false, skipNullOn="arrays"
----

==== Skip Null On (for JSON)

You can specify whether this generates an outbound message that contains fields with "null" values, or if these fields are ignored entirely. This can be set through an attribute in the output directive named `skipNullOn`, which can be set to three different values: `elements`, `attributes`, or `everywhere`.

When set to:

* `elements`: A key:value pair with a null value is ignored.
* `attributes`: An XML attribute with a null value is skipped.
* `everywhere`: Apply this rule to both elements and attributes.

=== Defining a Metadata Type (for JSON)

In the Transform component, you can define a JSON type through the following methods:

* By providing a sample file
* By pointing to a schema file

[[format_xml]]
== XML

Mime Type: `application/xml`

The XML data structure is mapped to DataWeave objects that can contain other objects as values to their keys. Repeated keys are supported. Example:

.Input
[source,xml,linenums]
----
<users>
  <company>MuleSoft</company>
  <user name="Leandro" lastName="Shokida"/>
  <user name="Mariano" lastName="Achaval"/>
</users>
----

.DataWeave Script
[source,dataweave,linenums]
----
{
  users: {
    company: "MuleSoft",
    user @(name: "Leandro",lastName: "Shokida"): "",
    user @(name: "Mariano",lastName: "Achaval"): ""
  }
}
----

=== Reader Properties (for XML)

When defining an input of type XML, there are a few optional parameters you can add in the XML definition of your Mule project to customize how the data is parsed.

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default |Description
|`optimizeFor`| string | speed | specifies the strategy to be used by the reader. Posible values = memory/speed
|`nullValueOn`|string | 'empty' |If a tag with empty or blank text should be read as null.
|`indexedReader`|boolean | true | Picks which reader modality to use. The indexed reader is faster but uses up a greater amount of memory, whilst the unindexed reader is slower but uses up less memory
|`maxEntityCount`|integer | 1 | Limits the number of times that an entity can be referenced within the XML code. This is included to guard against https://en.wikipedia.org/wiki/Billion_laughs[denial of service attacks].
|`externalEntities`|boolean | false | Defines if references to entities that are defined in a file outside the XML are accepted as valid. It's recommended to avoid these for https://www.owasp.org/index.php/XML_External_Entity_(XXE)_Processing[security reasons] as well.
|===


////
TODO: UPDATE

* XML example:
+
[source,xml,linenums]
----
<dw:transform-message metadata:id="33a08359-5085-47d3-aa5f-c7dd98bb9c61"
  doc:name="Transform">
    <dw:input-payload
      <!-- specifies the strategy to be used by the reader -->
      <dw:reader-property name="optimizeFor" value="speed" />
      <!-- If a tag with empty or blank text should be read as null. -->
      <dw:reader-property name="nullValueOn" value="empty" />
    </dw:input-payload>
    <dw:set-payload>
      <![CDATA[
        %dw 2.0
        output application/xml
        ---
        // Your transformation script goes here
      ]]>
    </dw:set-payload>
</dw:transform-message>
----
+
* Transform component
+
////

// TODO: is this available in studio 7?
//image:dataweave-formats-6e5e4.png[]

=== Writer Properties (for XML)

When defining an output of type XML, there are a few optional parameters you can add to the output directive to customize how the data is parsed:

[cols="2,1,1,2", options="header"]
|===
|Parameter |Type |Default|Description
|`indent`| boolean | true | Defines if the XML code will be indented for better readability, or if it will be compressed into a single line
| `inlineCloseOn` | string | `never` | Defines whether an empty XML child element appears as single self-closing tag or with an opening and closing tag. The value `empty` sets it to output self-closing tags.
|`encoding`|string | UTF-8 |The character set to be used for the output
|`bufferSize`| number | 153600 | The size of the buffer writer
|`inlineCloseOn` | string | | When the writer should use inline close tag. Possible values = `empty`/`none`
|`skipNullOn`| string | | Possible values = `elements`/`attributes`/`everywhere`. See <<Skip Null On>>
|`writeDeclaration`| boolean | true | Defines if the XML declaration will be included in the first line
|===

.Example: output Directive
[source,dataweave,linenums]
----
output application/xml indent=false, skipNullOn="attributes"
----

The `inlineCloseOn` parameter defines whether the output is structured like this (the default):

[source,xml,linenums]
----
<someXml>
  <parentElement>
    <emptyElement1></emptyElement1>
    <emptyElement2></emptyElement2>
    <emptyElement3></emptyElement3>
  </parentElement>
</someXml>
----

It can also be structured like this (set with a value of `empty`):

[source,xml,linenums]
----
<payload>
  <someXml>
    <parentElement>
      <emptyElement1/>
      <emptyElement2/>
      <emptyElement3/>
    </parentElement>
  </someXml>
</payload>
----

See also, xref:dataweave-cookbook-output-self-closing-xml-tags.adoc[Example: Outputting Self-closing XML Tags].

==== Skip Null On (for XML)

You can specify whether your transform generates an outbound message that contains fields with "null" values, or if these fields are ignored entirely. This can be set through an attribute in the output directive named `skipNullOn`, which can be set to three different values: `elements`, `attributes`, or `everywhere`.

When set to:

* `elements`: A key:value pair with a null value is ignored.
* `attributes`: An XML attribute with a null value is skipped.
* `everywhere`: Apply this rule to both elements and attributes.

=== Defining a Metadata Type (for XML)

In the Transform component, you can define a XML type through the following methods:

* By providing a sample file
* By pointing to a schema file

[[format_cdata]]
=== CData Custom Type (for XML)

Mime Type: `application/xml`

`CData` is a custom data type for XML that is used to identify a CDATA XML block. It can tell the writer to wrap the content inside CDATA or to check if the input string arrives inside a CDATA block. `CData` inherits from the type `String`.

.DataWeave Script
[source,dataweave,linenums]
----
%dw 2.0
output application/xml
---
{
  users:
  {
    user : "Mariano" as CData,
    age : 31 as CData
  }
}
----

.Output
[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>
<users>
  <user><![CDATA[Mariano]]></user>
  <age><![CDATA[31]]></age>
</users>
----

[[format_url_encoded]]
== URL Encoding

Mime Type: `application/x-www-form-urlencoded`

A URL encoded string is mapped to a DataWeave object:

* You can read the values by their keys using the dot or star selector.
* You can write the payloads by providing a DataWeave object.

Here is an example of `x-www-form-urlencoded` data:

[[raw_data]]
.Data
[source,text,linenums]
----
key=value&key+1=%40here&key=other+value&key+2%25
----

The following DataWeave script produces the data above:

.DataWeave Object
[source,dataweave,linenums]
----
output application/x-www-form-urlencoded
---
{
  "key" : "value",
  "key 1": "@here",
  "key" : "other value",
  "key 2%": null
}
----

You can read in the <<raw_data,data>> above as input to the DataWeave script in the next example to return `value@here` as the result.

.DataWeave Script
[source,dataweave,linenums]
----
output text/plain
---
payload.*key[0] ++ payload.'key 1'
----

Note that there are no reader properties for URL encoded data.

=== Writer (for URL Encoded Data)

Here is the DataWeave output directive for writing form data:

.Example: output Directive
[source,dataweave,linenums]
----
output application/x-www-form-urlencoded
----

In the output directive, you can also set a property for the writer to use when it outputs the data in the specified format.

// TODO: ASK SHOKI ABOUT KB VS BYTES
[cols="2,1,2", options="header"]
|===
|Parameter | Default |Description
|`encoding` | UTF-8 | Specifies the encoding to use.
|`bufferSize` | 192 kb | Specifies a number of bytes to use for the buffer.
|===

.Example: output Directive
[source,dataweave,linenums]
----
output application/x-www-form-urlencoded encoding="UTF-8", bufferSize="500"
----

Note that in the DataWeave `write` function, you can also pass the property as an optional parameter. The scope of the property is limited to the DataWeave script where you call the function.

== See Also

xref:7.1@studio::transform-message-component-concept-studio.adoc[About the Transform Message Component]

xref:dataweave-flat-file-schemas.adoc[Flat File Schemas]
