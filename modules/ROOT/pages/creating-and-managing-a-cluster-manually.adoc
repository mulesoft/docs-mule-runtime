= Creating and Managing a Cluster Manually
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]
:keywords: cluster, deploy

*_Enterprise Edition_*

This page describes manual creation and configuration of a cluster. There are three ways to create and manage clusters:

* Using the Mule Management Console's graphical interface.
* Using Runtime Manager - for more information, see xref:runtime-manager::managing-servers.adoc#create-a-cluster[Creating and Managing Clusters].
* Manually, using a configuration file.


[CAUTION]
====
Do not attempt mixed management of clusters.

If you create a cluster manually, do not attempt to manage it via the Management Console. The Management Console cannot recognize your manually-created cluster and overwrites your cluster configuration.
====

[NOTE]
====
All nodes in a cluster must have the same agent version.
====

== Creating a Cluster Manually

Follow this procedure to create a cluster manually, using a configuration file.

. Ensure that the node is not running, this means the Mule Runtime Server is stopped.
. Create a file named `mule-cluster.properties` inside the node's `$MULE_HOME/.mule` directory.
. Edit the file with parameter = value pairs, one per line. See the example below.

[NOTE]
====
`mule.clusterId` and `mule.clusterNodeId` must be in the `mule-cluster.properties` file.
====

[source,text,linenums]
----
...
mule.cluster.nodes=192.168.10.21,192.168.10.22,192.168.10.23
mule.cluster.multicastenabled=false
mule.clusterId=<Cluster_ID>
mule.clusterNodeId=<Cluster_Node_ID>
...
----

. Repeat this procedure for all Mule servers that you want to set in the cluster.
. Start the Mule servers in the nodes.

For the full list of available parameters, see <<Cluster Configuration Parameters>>.

== Managing a Cluster Manually

Manual management of a cluster is only possible for clusters that have been manually created, which are not managed by the Mule Management Console.

To manually change the configuration of a cluster node, follow these steps:

. Stop the node's Mule server.

. Edit the node's `mule-cluster.properties` as desired, then save the file.

. Restart the node's Mule server.

[CAUTION]
====
Ensure consistency across nodes.

Ensure that the options you apply in the configuration file are valid for all cluster nodes. Failure to do so can cause you to  break the cluster configuration and inadvertently disable the cluster.
====

=== Quorum management

When managing a manually configured cluster, you can now set a minimum quorum of machines required for the cluster to be operational.

When partitioning a network, clusters are available by default. However, by setting a minimum quorum size, you can configure your cluster to reject updates that do not pass a minimum threshold.
This helps you achieve better consistency and protects your cluster in case of an unexpected loss of one of your nodes (Mule Runtimes in the cluster).

Under normal circumstances, if a node were to die in the cluster, you may still have enough memory available to store your data, but the number of threads available to process requests would be reduced as you now would have fewer nodes available and the partition threads in the cluster could quickly become overwhelmed. This could lead to

* Clients left without threads to process their requests.
* The remaining members of the cluster become so overwhelmed with requests that theyâ€™re unable to respond and are forced out of the cluster on the assumption that they are dead.

To protect the rest of the cluster in the event of member loss, you can set a minimum quorum size to stop concurrent updates to your nodes, and throwing a +QuorumException+ whenever the number of active nodes in the cluster is below your configured value.

[CAUTION]
====
QuorumExceptions must be caught.

When configuring a Quorum Size for your cluster, you need to catch the thrown exception to make some sort of decision (for example, send an email, stop a process, logging, retry strategies, and so on)
====

To enable quorum, add the `mule.cluster.quorumsize` property to the cluster configurations file `{MULE_HOME}/.mule/mule-cluster.properties` defining the minimum number of nodes required to keep the cluster in an operational state.

[NOTE]
--
Quorum feature is only valid for components that use Object Store.
--

=== Object Store Persistence

You can persistently store JDBC data in a centralized system, accessible from all cluster nodes.

[TIP]
--
Check xref:hardware-and-software-requirements.adoc#mule-database-servers[Mule's hardware and software requirements] for a list of supported relational database management systems.

Keep in mind that, from that list, Oracle database support is a xref:release-notes::mule-runtime/mule-3.8.0-release-notes.adoc#enterprise-edition-known-issues-and-limitations[known limitation] for Mule 3.8.x and it is planned for a future release.
--

To enable Object store persistence, you need to create a database and define its configuration values in the `{MULE_HOME}/.mule/mule-cluster.properties` file:

. `mule.cluster.jdbcstoreurl`: The JDBC URL for connecting to the database
. `mule.cluster.jdbcstoreusername`: Database username
. `mule.cluster.jdbcstorepassword`: Database user password
. `mule.cluster.jdbcstoredriver`: JDBC Driver class name
. `mule.cluster.jdbcstorequerystrategy`:  SQL dialect

The database's tables are created automatically, as this feature creates tables for each different object store that you want to persist.
Two tables are created per object store:

* One table stores data
* Another table stores partitions.

==== Recommendations for the Object Store Database

* Mulesoft recommends that you create a dedicated database/schema that will only be used for the JDBC store.
* The database username needs:
** Permission to create objects in the database, which means DDL CREATE, DROP for tables.
** DML permissions on the objects it creates (INSERT, UPDATE, DELETE, SELECT)
* Always keep in mind that the data storage needs to be hosted in a centralized database reachable from all nodes. Don't use more than one database per cluster. +
Check the <<persistency-config,cluster configuration reference for persistency>> for details on how to configure these values.
* Some relational databases have certain constraints regarding the name length of tables. Use the `mule.cluster.jdbcstoretableNametransformerstrategy` property to transform long table names into shorter values. +
Check the <<table-name-transformers, Table Name Transformers>> section for more details on how to configure this property.

[[table-name-transformers]]
===== Table Name Transformers

The `mule.cluster.jdbcstoretableNametransformerstrategy` property allows you to define a custom transformer to modify table names.

For example, if you set the following property in `mule-cluster.properties`:
[source]
----
...
mule.cluster.jdbcstoretableNametransformerstrategy=com.mulesoft.mule.cluster.hazelcast.persistence.query.MD5TableNameTransformerStrategy
...
----
The table names will be hashed using MD5 and a prefix to identify that these are Mule tables. Hashing table names guarantees that the length constraint is honored.

Optionally, you can create a custom transformer strategy by implementing the `com.mulesoft.mule.cluster.hazelcast.persistence.query.TableNameTransformerStrategy` interface.

=== Monitoring

You can monitor the events thrown by the cluster members through the http://www.oracle.com/technetwork/java/javase/tech/javamanagement-140525.html[JMX technology].

The JMX monitoring option is disabled by default. To enable it, you need to add the `mule.cluster.jmxenabled` property to the `{MULE_HOME}/.mule/mule-cluster.properties` configuration file.

Please note that enabling JMX might cause some performance overheads given that the underlying structure adds listeners to get the statistics for each individual node.


=== Membership Listener

The membership listener allows you to get notifications whenever:

. A new member is added to the cluster.
. An existing member leaves the cluster.

When one of these events is triggered, the membership listener outputs the addresses of the members that joined or left respectively.

== Cluster Configuration Parameters

The following table lists the parameters of the `mule-cluster.properties` file.

[%header%autowidth.spread]
|===
|Property name |Description
|`mule.clusterId` |Mandatory. Unique identifier for the cluster. It can be any alphanumeric string.
|`mule.clusterNodeId` |Mandatory. The unique ID of the node within the cluster. It can be any integer between 1 and the number of nodes in the cluster.
|`mule.cluster.networkinterfaces` a|
Comma-separated list of interfaces to use by Hazelcast. Wildcards are supported, as shown below.

----
192.168.1.*,192.168.100.25
----

|`mule.cluster.nodes` a|
The nodes that belong to the cluster, in the form `<host:port>`, for example, `172.16.9.24:9000`. Specifying just one IP address enables the server to join the cluster.

The port number is optional; if not set, the default is 5701. To include more than one host, create a comma-separated list.

This option configures the cluster with the specified fixed IP addresses. Use this option if you are not relying on multicast for cluster node discovery. If using this option, set `mule.cluster.multicastenabled` to `false`. Otherwise, an exception is thrown when you start the cluster. (see next item in this table).

Examples:

Two nodes listening on port 9000:

----
172.16.9.24:9000,172.16.9.51:9000
----

Two nodes listening on port 5701:

----
192.168.1.19,192.168.1.20
----

|`mule.cluster.quorumsize` | Enables you to define the minimum number of machines required in a cluster to remain in an operational state.
|`mule.cluster.multicastenabled` |(Accepted values: `true` or `false`) Enable/disable multicast. Set to `false` if using fixed IP addresses for cluster node discovery (see option `mule.cluster.nodes` above). +
If set to `true`, do not set IP addresses in `mule.cluster.nodes`.
|`mule.cluster.multicastgroup` |Multicast group IP address to use.
|`mule.cluster.multicastport` |Multicast port number to use.
| [[persistency-config]] `mule.cluster.jdbcstoreurl` | Required only when storing persistent data. +
The JDBC URL for connection to the database.
|`mule.cluster.jdbcstoreusername` |Required only when storing persistent data. +
Database username.
|`mule.cluster.jdbcstorepassword` |Required only when storing persistent data. +
Database user password.
|`mule.cluster.jdbcstoredriver` |Required only when storing persistent data. +
JDBC Driver class name.
|`mule.cluster.jdbcstorequerystrategy` |Required only when storing persistent data. +
SQL dialect for accessing the stored object data. +
This property can take one of three different values: `mssql`, `mysql`, and `postgresql`.
|`mule.cluster.jdbcstoretableNametransformerstrategy` | Allows you to define a custom transformer to modify table names.
|`mule.cluster.jmxenabled` | (Accepted values: `true` or `false`) Enable/disable monitoring.
|`mule.cluster.listenersenabled` | (Accepted values: `true` or `false`) Enable/disable membership listener. Set to `true` if you want your nodes to get notified when a member enters or leaves the cluster.
|===
