= Complete Batch Example
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

This article goes through the https://anypoint.mulesoft.com/exchange/org.mule.examples/import-leads-into-salesforce/[Import Leads into Salesforce using Batch Processing] example in Exchange and explains how batch processing executes in a Mule application.

The sample application takes a CSV file of leads and uploads the lead information to an active Salesforce user account. It uses DataSense and the Transform Message processor to map and transform data, thereby facilitating a quick integration with this Software as a Service (SaaS) provider.

== Before you Begin

* You need a Salesforce developer account. +
If you don't have one, you can create one by signing up in +developer.salesforce.com+.
* You need to reset your Salesforce security token.
+
. Log in to your Salesforce developer account.
. In the top navigation bar, click on your name and select *My Settings*.
. In the left navigation bar, select *Personal*, and *Reset My Security Token*.
. Click the *Reset Security Token*. +
Salesforce will send you an email with your new security token.
* You need the latest Studio version installed in your machine. +
Follow the xref:7.2@studio::to-download-and-install-studio.adoc[To Download and Install Anypoint Studio] tutorial.
* Download the https://anypoint.mulesoft.com/exchange/org.mule.examples/import-leads-into-salesforce/[Import Leads into Salesforce using Batch Processing] example from Exchange.

== Setting up the Example

. Open Anypoint Studio.
. Download the https://anypoint.mulesoft.com/exchange/org.mule.examples/import-leads-into-salesforce/[Import Leads into Salesforce using Batch Processing]. +
See xref:exchange::to-download-an-asset.adoc[To Download an Asset] for more information.
. Import your downloaded example into Studio. +
See xref:7.2@studio::import-export-packages.adoc[Importing and Exporting Projects] for more information. +
Additionally, you can import this very same example from Studio. See xref:7.2@studio::import-project-exchange.adoc[To Import a Mule Project from Exchange] for more details.
. Open the *mule-artifact.properties* file inside the src/main/resources folder and complete the `sfdc.user`, `sfdc.password`, and `sfdc.securityToken` with your Salesforce's username, password and security token respectively.

== Batch Example Code

The application accepts a CSV file which contains information about the leads you want to insert – company, first name, last name, birthday, email – and uploads them into a Salesforce account, automatically inserting the correct data into each Salesforce field.

.Batch example in the Studio canvas.
image::batch-code-exmaple-10b3f.png[]

The File connector polls the input folder for new files every ten seconds. When it spots a new file, it reads it and passes the content to the Transform Message processor. +
This processor converts the format of the data from CSV to a collection, and it automatically maps the input fields from the CSV file – FirstName, LastName, etc. – to output fields that Salesforce uses in a collection.

.XML Sample of the application setting up the data
[source,xml,linenums]
----
<flow name="import-leads-into-salesforceFlow" >

  <scheduler>
    <scheduling-strategy>
      <fixed-frequency frequency="${scheduler.frequency}" startDelay="${scheduler.startDelay}" />
    </scheduling-strategy>
  </scheduler>

  <file:read config-ref="File_Config" path="leads.csv" outputMimeType="text/csv">
    <ee:repeatable-file-store-stream />
  </file:read>

  <ee:transform doc:name="Transform CSV to Maps">
    <ee:message>
      <ee:set-payload>
        <![CDATA[%dw 2.0
        output application/java
        ---
        payload map {
          Company    : $.company,
          Email      : $.email,
          FirstName  : $.firstName,
          LastName   : $.lastName
        }]]>
      </ee:set-payload>
    </ee:message>
  </ee:transform>
----

After all leads in the file are converted to a collection of Salesforce-friendly data, the application uses a batch job scope to go through each lead in the CSV file and insert it into your Salesforce account.
It starts with the batch step `LeadExistsStep`, where a Salesforce Connector queries for existing leads. Note that it uses a target variable called "leadNotFound" to store the CSV lead values that were not found in your Salesforce account.

[source,xml,linenums]
----
<batch:job jobName="CreateLeadsBatch" maxFailedRecords="1000">
  <batch:process-records >
    <batch:step name="LeadExistsStep">
      <salesforce:query config-ref="Salesforce_Sfdc_config" target="leadNotFound" targetValue="#[isEmpty(payload)]">
        <salesforce:salesforce-query >SELECT Id FROM Lead WHERE Email = ':email'</salesforce:salesforce-query>
        <salesforce:parameters >
          <![CDATA[#[output applicaton/java
          ---
          {
            "email" : payload.Email
          }]]]>
        </salesforce:parameters>
        </salesforce:query>
    </batch:step>
----

The second batch step, `LeadInsertStep` uses an expression filter to process only the leads that were not found in your Salesforce account. It logs the records to process, and then uses a batch aggregator to accumulate up to 200 leads and pushes them to your Salesforce account.

[source,xml,linenums]
----
    <batch:step name="LeadInsertStep" acceptExpression="vars.leadNotFound">
      <logger level="INFO" doc:name="Log the lead" message="#['Processing new record: ' ++ write(payload, 'application/json', {'indent': 'false'})]"/>

      <batch:aggregator size="200">
        <logger level="INFO" message="#[payload]"/>
        <salesforce:create config-ref="Salesforce_Sfdc_config" type="Lead"/>
      </batch:aggregator>
    </batch:step>
----

The application then uses the `LogFailuesStep` to log the leads that failed to upload. Note that this step uses the acceptPolicy filter attribute with the ONLY_FAILURES value.

[source,xml,linenums]
----
    <batch:step name="LogFailuresStep" acceptPolicy="ONLY_FAILURES">
      <logger level="ERROR" message="#['Failure: ' ++  write(payload, 'application/json', {'indent': 'false'})]"/>
    </batch:step>
  </batch:process-records>
----

Finally, during the On-Complete phase, the batch job logs the processed records, which ones failed, and which ones were successfully pushed to your Salesforce account.

[source,xml,linenums]
----
  <batch:on-complete >
    <logger level="INFO" message="#[payload.loadedRecords ++ ' Loaded Records ' ++ payload.failedRecords ++' Failed Records']"/>
  </batch:on-complete>
</batch:job>

</flow>
----

== See Also

* xref:batch-processing-concept.adoc[Batch Processing]
* xref:batch-filters-and-batch-aggregator.adoc[Refining Batch Steps Processing]
